{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import requests\n",
    "\n",
    "text_by_file = utils.load_files('./ustawy/*')\n",
    "\n",
    "for file,text in text_by_file.items():\n",
    "    text_by_file[file] = ' '.join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the classification of [Named Entities](https://clarin-pl.eu/dspace/bitstream/handle/11321/294/WytyczneKPWr-jednostkiidentyfikacyjne.pdf).\n",
    "1. Read the [API of NER](https://wiki.clarin-pl.eu/pl/nlpws/services/liner2) in [Clarin](https://ws.clarin-pl.eu/ner.shtml).\n",
    "1. Read the [documentation of CCL format](https://wiki.clarin-pl.eu/pl/nlpws/services/ccl) or [more tourough documentation of CCL format](http://nlp.pwr.wroc.pl/redmine/projects/corpus2/wiki/CCL_format).\n",
    "1. Sort bills according to their size and take top 50 (largest) bills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['./ustawy/2000_696.txt', './ustawy/2001_627.txt', './ustawy/1996_465.txt', './ustawy/2002_1689.txt', './ustawy/1997_555.txt', './ustawy/1998_1118.txt', './ustawy/2000_1186.txt', './ustawy/2003_2277.txt', './ustawy/2003_1750.txt', './ustawy/2001_1070.txt', './ustawy/2001_499.txt', './ustawy/1997_117.txt', './ustawy/2004_2065.txt', './ustawy/2001_1368.txt', './ustawy/2004_1693.txt', './ustawy/2001_1229.txt', './ustawy/2000_1268.txt', './ustawy/1997_926.txt', './ustawy/1994_195.txt', './ustawy/2001_1545.txt', './ustawy/2004_880.txt', './ustawy/2004_177.txt', './ustawy/2003_423.txt', './ustawy/2000_1104.txt', './ustawy/1997_714.txt', './ustawy/1997_553.txt', './ustawy/1997_349.txt', './ustawy/1994_591.txt', './ustawy/2004_2533.txt', './ustawy/2001_1381.txt', './ustawy/1999_930.txt', './ustawy/2000_1315.txt', './ustawy/2000_136.txt', './ustawy/1999_95.txt', './ustawy/1996_460.txt', './ustawy/2003_2256.txt', './ustawy/1997_557.txt', './ustawy/1996_110.txt', './ustawy/1996_561.txt', './ustawy/2001_628.txt', './ustawy/2001_1438.txt', './ustawy/1998_602.txt', './ustawy/2001_475.txt', './ustawy/2003_1692.txt', './ustawy/2002_1070.txt', './ustawy/2001_1188.txt', './ustawy/2001_906.txt', './ustawy/1997_153.txt', './ustawy/2001_92.txt', './ustawy/2003_2276.txt'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sorted = {k: v for k, v in sorted(text_by_file.items(), key=lambda item: len(item[1]), reverse=True)[:50]}\n",
    "text_sorted.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for file in text_sorted.keys():\n",
    "    shutil.copy(file, 'ustawy_top_50')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use the lemmatized and sentence split documents (from ex. 5) to identify the expressions that consist of consecutive\n",
    "   words starting with a capital letter (you will have to look at the inflected form of the word to check its\n",
    "   capitalization) that do not occupy the first position in a sentence. E.g. the sentence:\n",
    "   ```\n",
    "   Wczoraj w Krakowie miało miejsce spotkanie prezydentów Polski i Stanów Zjednoczonych.\n",
    "   ```\n",
    "   should yield the following entries: `Kraków`, `Polska`, `Stan Zjednoczony`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_files = ['./ustawy_lem/' + '%'.join(f.split('/')[1:]) for f in text_sorted.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "\n",
    "def parse_xml(path: str) -> list[str]:\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    sentences = []\n",
    "    \n",
    "    for chunk in root.iter('chunk'):\n",
    "        sentences.append(list(chunk.iter('sentence')))\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def parse_files(paths: list[str]) -> dict[str, str]:\n",
    "    files = []\n",
    "\n",
    "    for file in paths:\n",
    "        files.append(parse_xml(file))\n",
    "\n",
    "    return files\n",
    "\n",
    "files_xml = parse_files(lem_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ne_in_sentence(sentence):\n",
    "    nes = []\n",
    "    ne = ''\n",
    "    toks = list(sentence.iter('tok'))\n",
    "    for tok in toks[1:]:\n",
    "        orth = tok.find('orth').text\n",
    "        base = tok.find('lex').find('base').text\n",
    "        if (orth[0].isupper() or (ne != '' and orth == '.')) and orth not in ['Dz','U','Art','Poz']: # Dz.U. is technically a NE\n",
    "            ne += base + ' '\n",
    "        elif ne != '':\n",
    "            nes.append(ne)\n",
    "            ne = ''\n",
    "    return nes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minister ',\n",
       " 'nr ',\n",
       " 'minister sprawa wewnętrzny ',\n",
       " 'minister ',\n",
       " 'minister sprawa wewnętrzny ',\n",
       " 'minister ',\n",
       " 'prawa ',\n",
       " 'nr ',\n",
       " 'minister sprawa wewnętrzny ',\n",
       " 'administracja ']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nes = [ne for chunk in files_xml for sentences in chunk for sentence in sentences for ne in find_ne_in_sentence(sentence)]\n",
    "nes[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compute the frequency of each identified expression and print 50 results with the largest number of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nr ', 4778), ('rzeczpospolita polski ', 587), ('kodeks ', 522), ('policja ', 384), ('skarb państwo ', 320), ('prawo ', 298), ('unia europejski ', 291), ('kasa chora ', 261), ('straż graniczny ', 258), ('minister ', 255), ('prezes urząd ', 242), ('zmiana ', 205), ('państwowy straż pożarny ', 201), ('zakład ', 196), ('pozostały ', 179), ('rad minister ', 170), ('fundusz ', 165), ('sprawiedliwość ', 163), ('państwowy komisja wyborczy ', 161), ('rad ', 157), ('obrona narodowy ', 156), ('w ', 152), ('urząd patentowy ', 152), ('EFTA ', 151), ('minister sprawiedliwość ', 144), ('europejski porozumienie ', 141), ('Wolny handel ', 140), ('tkanina ', 138), ('minister obrona narodowy ', 136), ('europejski obszar gospodarczy ', 128), ('finanse ', 115), ('SKW ', 115), ('i ', 113), ('urząd ', 110), ('przepis ', 102), ('komisja ', 101), ('biuro ', 98), ('inspektor nadzór wewnętrzny ', 93), ('damski ', 91), ('SWW ', 88), ('ordynacja ', 86), ('opieka społeczny ', 84), ('urząd ochrona państwo ', 81), ('okręgowy komisja wyborczy ', 81), ('II ', 80), ('Rzeczpospolita Polska ', 80), ('L ', 80), ('prezes rad minister ', 76), ('zakład ubezpieczenie społeczny ', 76), ('komisja europejski ', 75)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "nes_freq = Counter(nes)\n",
    "\n",
    "a = sorted(nes_freq.items(), key=lambda item: item[1], reverse=True)[:50]\n",
    "print(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'rzeczpospolita polski' i 'Rzeczpospolita Polska' - z jakiegoś powodu w zależności od przypadku 'Polski' we frazie jest ona przez Clarin traktowana inaczej: \n",
    "\n",
    "'Rzeczpospolitej Polskiej' -> 'rzeczpospolita polski'\n",
    "\n",
    "'Rzeczpospolita Polska', 'Rzeczpospolitą Polską' -> 'Rzeczpospolita Polska'\n",
    "\n",
    "przykład [`ustawy%2004_963.txt`](./ustawy_lem/ustawy%252004_963.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Apply the NER algorithm to identify the named entities in the same set of documents (not lemmatized) using the `n82` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lpmn_client import download_file, upload_file\n",
    "from lpmn_client import Task\n",
    "\n",
    "# not working, use web page instead\n",
    "task = Task(lpmn='any2txt|wcrft2|liner2({\"model\":\"n82\"})')\n",
    "task.email = \"pawel.kopel2@gmail.com\"  # change e-mail\n",
    "\n",
    "file_id = upload_file(\"./ustawy_top_50.zip\")\n",
    "output_file_id = task.run(file_id)\n",
    "download_file(output_file_id, \"./ustawy_top_50_nes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Plot the frequency (histogram) of the coarse-grained classes (e.g. `nam_adj`, `nam_eve`, `nam_fac`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Display 10 most frequent Named Entities for each coarse-grained type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Display 50 most frequent Named Entities including their count and fine-grained type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Display 5 sentences containing at least 2 recognized named entities with different types. Highlight the recognized spans with color.\n",
    "   (For demo application [Streamlit](https://streamlit.io/) might be useful for displaying NER results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Answer the following questions:\n",
    "      1. Which of the method (counting expressions with capital letters vs. NER) worked better for the task concerned with\n",
    "         identification of the proper names?\n",
    "      1. What are the drawbacks of the method based on capital letters?\n",
    "      1. What are the drawbacks of the method based on NER?\n",
    "      1. Which of the coarse-grained NER groups has the best and which has the worst results? Try to justify this\n",
    "         observation.\n",
    "      1. Do you think NER is sufficient for identifying different occurrences of the same entity (i.e. consider \"USA\" and\n",
    "         \"Stany Zjednoczone\" and \"Stany Zjednoczone Ameryki Północnej\")? If not, can you suggest an algorithm or a tool that\n",
    "         would be able to group such names together?\n",
    "      1. Can you think of a real world problem that would benefit the most from application of Named Entity Recognition\n",
    "         algorithm?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
