{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 22:52:50.073019: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:52:50.461417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-30 22:52:50.461442: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-30 22:52:50.528432: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-30 22:52:51.819612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-30 22:52:51.819709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-30 22:52:51.819718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the documentation of [Language modelling in the Transformers](https://huggingface.co/transformers/task_summary.html#language-modeling) library.\n",
    "1. Download three [Polish models](https://huggingface.co/models?filter=pl) from the Huggingface repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03835701942443848,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 625,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fff5d60d2654309bf8d6484ad36f1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018355846405029297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 714314041,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9df012a1ba84edfac6cdf720dab7ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018049240112304688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 29,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891f12029abf44929f779f2e0be7b76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.029096126556396484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 995526,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d43543a4cdd448e9933e50303eb28df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018416881561279297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1961828,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0198ddccab0402ea6a62adea7055fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01629018783569336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 615,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286fb174924c42198accf789dc678902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019153356552124023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1115590446,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a43eb92d5554d6d843b365e25026064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016047000885009766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 5069051,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3361301ed9740b990fdfe5858a7540c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025322914123535156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 9096718,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c840d8a6c54f434fa31e8ef8d9507054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.030503511428833008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 466,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbe73f41b4a47889c03ba670f7e1123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012038707733154297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 541808922,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7cbd0606bc46c6a7da4dca2834e370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0333552360534668,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 29,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ed465b7b4745a38691a5209ac8f422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02631831169128418,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 995526,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5d56e0db5d4d1f86ecd750fdf7e01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01594066619873047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1961828,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c122ce623000486cb8afe824b2dc3563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "    ('bert-base-multilingual-cased', '[MASK]'),\n",
    "    ('xlm-roberta-base', '<mask>'),\n",
    "    ('distilbert-base-multilingual-cased', '[MASK]')\n",
    "]\n",
    "\n",
    "unmaskers = list(\n",
    "    map(lambda model, mask: (model, pipeline('fill-mask', model=model), mask), *zip(*models))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmaskers_x, masks_x = zip(*unmaskers)\n",
    "names_x, _ = zip(*models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bert-base-multilingual-cased',\n",
       "  <transformers.pipelines.fill_mask.FillMaskPipeline at 0x7fe456b308b0>,\n",
       "  '[MASK]'),\n",
       " ('xlm-roberta-base',\n",
       "  <transformers.pipelines.fill_mask.FillMaskPipeline at 0x7fe456c22980>,\n",
       "  '<mask>'),\n",
       " ('distilbert-base-multilingual-cased',\n",
       "  <transformers.pipelines.fill_mask.FillMaskPipeline at 0x7fe4546d7f40>,\n",
       "  '[MASK]')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmaskers = list(zip(names_x, unmaskers_x, masks_x))\n",
    "unmaskers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = '[[mask]]'\n",
    "\n",
    "def test_sentences(sentences: list[str]):\n",
    "    for sentence in sentences:  \n",
    "        print('#'*20)\n",
    "        for name, unmasker, mask in unmaskers:\n",
    "            sentence_m = sentence.replace(MASK,mask)\n",
    "            print(f'{name}:', end='')\n",
    "            for result in unmasker(sentence_m):\n",
    "                print(f'\\t{result[\"sequence\"]}', end='')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Devise a method to test if the langage model understands Polish cases. E.g. testing for *nominal case* could be expressed as \"Warszawa to największe `[MASK]`\", and the masked word should be in nominative case. Create sentences for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    f'{MASK} jest popularnym owocem', # mianownik\n",
    "    f'Nie ma tutaj z nami {MASK}', # dopełniacz\n",
    "    f'Przyglądam się {MASK} od godziny', # celownik\n",
    "    f'Czy widziałeś ostatnio {MASK}', # biernik\n",
    "    f'Obszar gnuśności zalany {MASK}', # narzędnik\n",
    "    f'Rozmawialiśmy z nimi o {MASK}', # miejscownik\n",
    "    f'{MASK} dodaj mi skrzydła', # wołacz\n",
    "]\n",
    "\n",
    "sentences_adj = [\n",
    "    f'Czerwony {MASK} jest popularnym owocem', # mianownik\n",
    "    f'Nie ma tutaj z nami naszego {MASK}', # dopełniacz\n",
    "    f'Przyglądam się pięknemu {MASK} od godziny', # celownik\n",
    "    f'Czy widziałeś ostatnio niebieski {MASK}', # biernik\n",
    "    f'Poszedłem na spacer z moim {MASK}', # narzędnik\n",
    "    f'Rozmawialiśmy z nimi o pięknych {MASK}', # miejscownik\n",
    "    f'{MASK} dodaj mi skrzydła', # wołacz\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "bert-base-multilingual-cased:\tjest jest popularnym owocem\tnie jest popularnym owocem\t- jest popularnym owocem\tta jest popularnym owocem\t, jest popularnym owocem\n",
      "xlm-roberta-base:\tNie jest popularnym owocem\tnie jest popularnym owocem\tDlaczego jest popularnym owocem\tTo jest popularnym owocem\tktóry jest popularnym owocem\n",
      "distilbert-base-multilingual-cased:\tHerb jest popularnym owocem\tNie jest popularnym owocem\tObecnie jest popularnym owocem\tMiasto jest popularnym owocem\tFilm jest popularnym owocem\n",
      "####################\n",
      "bert-base-multilingual-cased:\tNie ma tutaj z nami.\tNie ma tutaj z nami,\tNie ma tutaj z nami ;\tNie ma tutaj z nami :\tNie ma tutaj z nami?\n",
      "xlm-roberta-base:\tNie ma tutaj z nami...\tNie ma tutaj z nami.\tNie ma tutaj z nami\tNie ma tutaj z nami!\tNie ma tutaj z nami?\n",
      "distilbert-base-multilingual-cased:\tNie ma tutaj z nami?\tNie ma tutaj z nami!\tNie ma tutaj z nami :\tNie ma tutaj z nami.\tNie ma tutaj z nami nie\n",
      "####################\n",
      "bert-base-multilingual-cased:\tPrzyglądam się, od godziny\tPrzyglądam się : od godziny\tPrzyglądam się to od godziny\tPrzyglądam się - od godziny\tPrzyglądam się od od godziny\n",
      "xlm-roberta-base:\tPrzyglądam się codziennie od godziny\tPrzyglądam się już od godziny\tPrzyglądam się Ci od godziny\tPrzyglądam się ci od godziny\tPrzyglądam się często od godziny\n",
      "distilbert-base-multilingual-cased:\tPrzyglądam się tylko od godziny\tPrzyglądam się dopiero od godziny\tPrzyglądam się jeszcze od godziny\tPrzyglądam się nawet od godziny\tPrzyglądam się nie od godziny\n",
      "####################\n",
      "bert-base-multilingual-cased:\tCzy widziałeś ostatnio.\tCzy widziałeś ostatnio,\tCzy widziałeś ostatnio :\tCzy widziałeś ostatnio ;\tCzy widziałeś ostatnio -\n",
      "xlm-roberta-base:\tCzy widziałeś ostatnio?\tCzy widziałeś ostatnio...\tCzy widziałeś ostatnio:\tCzy widziałeś ostatnio\tCzy widziałeś ostatnio...\n",
      "distilbert-base-multilingual-cased:\tCzy widziałeś ostatnio?\tCzy widziałeś ostatnio!\tCzy widziałeś ostatnio :\tCzy widziałeś ostatnio.\tCzy widziałeś ostatnio,\n",
      "####################\n",
      "bert-base-multilingual-cased:\tObszar gnuśności zalany.\tObszar gnuśności zalany :\tObszar gnuśności zalany,\tObszar gnuśności zalany ;\tObszar gnuśności zalany jest\n",
      "xlm-roberta-base:\tObszar gnuśności zalany.\tObszar gnuśności zalany\tObszar gnuśności zalany...\tObszar gnuśności zalany?\tObszar gnuśności zalany,\n",
      "distilbert-base-multilingual-cased:\tObszar gnuśności zalany :\tObszar gnuśności zalanyczy\tObszar gnuśności zalanycza\tObszar gnuśności zalany wody\tObszar gnuśności zalany.\n",
      "####################\n",
      "bert-base-multilingual-cased:\tRozmawialiśmy z nimi o tym\tRozmawialiśmy z nimi o.\tRozmawialiśmy z nimi o innych\tRozmawialiśmy z nimi o nim\tRozmawialiśmy z nimi o wiele\n",
      "xlm-roberta-base:\tRozmawialiśmy z nimi o:\tRozmawialiśmy z nimi o...\tRozmawialiśmy z nimi o pracy\tRozmawialiśmy z nimi o...\tRozmawialiśmy z nimi o\n",
      "distilbert-base-multilingual-cased:\tRozmawialiśmy z nimi o :\tRozmawialiśmy z nimi o sobie\tRozmawialiśmy z nimi o czym\tRozmawialiśmy z nimi o tym\tRozmawialiśmy z nimi o niej\n",
      "####################\n",
      "bert-base-multilingual-cased:\t- dodaj mi skrzydła\tNie dodaj mi skrzydła\tnie dodaj mi skrzydła\t, dodaj mi skrzydła\tTak dodaj mi skrzydła\n",
      "xlm-roberta-base:\tdodaj mi skrzydła\tNie dodaj mi skrzydła\t» dodaj mi skrzydła\t- dodaj mi skrzydła\t+ dodaj mi skrzydła\n",
      "distilbert-base-multilingual-cased:\tJak dodaj mi skrzydła\tNie dodaj mi skrzydła\tGdy dodaj mi skrzydła\tnie dodaj mi skrzydła\tIch dodaj mi skrzydła\n"
     ]
    }
   ],
   "source": [
    "test_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "bert-base-multilingual-cased:\tCzerwony herb jest popularnym owocem\tCzerwony most jest popularnym owocem\tCzerwony list jest popularnym owocem\tCzerwony pan jest popularnym owocem\tCzerwony Herb jest popularnym owocem\n",
      "xlm-roberta-base:\tCzerwony pieprz jest popularnym owocem\tCzerwony róż jest popularnym owocem\tCzerwony sok jest popularnym owocem\tCzerwony pomidor jest popularnym owocem\tCzerwony granat jest popularnym owocem\n",
      "distilbert-base-multilingual-cased:\tCzerwony رنگ jest popularnym owocem\tCzerwony Ｃ jest popularnym owocem\tCzerwony gaz jest popularnym owocem\tCzerwony Jerzy jest popularnym owocem\tCzerwony музея jest popularnym owocem\n",
      "####################\n",
      "bert-base-multilingual-cased:\tNie ma tutaj z nami naszego.\tNie ma tutaj z nami naszego,\tNie ma tutaj z nami naszego :\tNie ma tutaj z nami naszego -\tNie ma tutaj z nami naszego ;\n",
      "xlm-roberta-base:\tNie ma tutaj z nami naszego domu\tNie ma tutaj z nami naszego serca\tNie ma tutaj z nami naszego Boga\tNie ma tutaj z nami naszego życia\tNie ma tutaj z nami naszego pokoju\n",
      "distilbert-base-multilingual-cased:\tNie ma tutaj z nami naszego dnia\tNie ma tutaj z nami naszego!\tNie ma tutaj z nami naszego brata\tNie ma tutaj z nami naszego syna\tNie ma tutaj z nami naszego :\n",
      "####################\n",
      "bert-base-multilingual-cased:\tPrzyglądam się pięknemu, od godziny\tPrzyglądam się pięknemu - od godziny\tPrzyglądam się pięknemu : od godziny\tPrzyglądam się pięknemu od od godziny\tPrzyglądam się pięknemu... od godziny\n",
      "xlm-roberta-base:\tPrzyglądam się pięknemu domu od godziny\tPrzyglądam się pięknemu polu od godziny\tPrzyglądam się pięknemu słońca od godziny\tPrzyglądam się pięknemu parku od godziny\tPrzyglądam się pięknemu dniu od godziny\n",
      "distilbert-base-multilingual-cased:\tPrzyglądam się pięknemu czasu od godziny\tPrzyglądam się pięknemu dnia od godziny\tPrzyglądam się pięknemu dopiero od godziny\tPrzyglądam się pięknemu, od godziny\tPrzyglądam się pięknemu tylko od godziny\n",
      "####################\n",
      "bert-base-multilingual-cased:\tCzy widziałeś ostatnio niebieski.\tCzy widziałeś ostatnio niebieski,\tCzy widziałeś ostatnio niebieski :\tCzy widziałeś ostatnio niebieski -\tCzy widziałeś ostatnio niebieski ;\n",
      "xlm-roberta-base:\tCzy widziałeś ostatnio niebieski?\tCzy widziałeś ostatnio niebieski...\tCzy widziałeś ostatnio niebieski?\tCzy widziałeś ostatnio niebieski???\tCzy widziałeś ostatnio niebieski??\n",
      "distilbert-base-multilingual-cased:\tCzy widziałeś ostatnio niebieski?\tCzy widziałeś ostatnio niebieski :\tCzy widziałeś ostatnio niebieski!\tCzy widziałeś ostatnio niebieski.\tCzy widziałeś ostatnio niebieski ;\n",
      "####################\n",
      "bert-base-multilingual-cased:\tPoszedłem na spacer z moim.\tPoszedłem na spacer z moim,\tPoszedłem na spacer z moim -\tPoszedłem na spacer z moim :\tPoszedłem na spacer z moim ;\n",
      "xlm-roberta-base:\tPoszedłem na spacer z moim dzieckiem\tPoszedłem na spacer z moim...\tPoszedłem na spacer z moim...\tPoszedłem na spacer z moim\tPoszedłem na spacer z moim autem\n",
      "distilbert-base-multilingual-cased:\tPoszedłem na spacer z moim?\tPoszedłem na spacer z moim synem\tPoszedłem na spacer z moim!\tPoszedłem na spacer z moim stanie\tPoszedłem na spacer z moim 髏\n",
      "####################\n",
      "bert-base-multilingual-cased:\tRozmawialiśmy z nimi o pięknych.\tRozmawialiśmy z nimi o pięknych :\tRozmawialiśmy z nimi o pięknych,\tRozmawialiśmy z nimi o pięknych...\tRozmawialiśmy z nimi o pięknych -\n",
      "xlm-roberta-base:\tRozmawialiśmy z nimi o pięknych miejscach\tRozmawialiśmy z nimi o pięknych...\tRozmawialiśmy z nimi o pięknych\tRozmawialiśmy z nimi o pięknych...\tRozmawialiśmy z nimi o pięknych.\n",
      "distilbert-base-multilingual-cased:\tRozmawialiśmy z nimi o pięknych :\tRozmawialiśmy z nimi o pięknych.\tRozmawialiśmy z nimi o pięknych dzieci\tRozmawialiśmy z nimi o pięknych?\tRozmawialiśmy z nimi o pięknych!\n",
      "####################\n",
      "bert-base-multilingual-cased:\tChodź tutaj wspaniały.\tChodź tutaj wspaniały,\tChodź tutaj wspaniały świat\tChodź tutaj wspaniały :\tChodź tutaj wspaniały język\n",
      "xlm-roberta-base:\tChodź tutaj wspaniały\tChodź tutaj wspaniały!\tChodź tutaj wspaniały...\tChodź tutaj wspaniały...\tChodź tutaj wspaniały.\n",
      "distilbert-base-multilingual-cased:\tChodź tutaj wspaniały :\tChodź tutaj wspaniały Biôgrafia\tChodź tutaj wspaniały?\tChodź tutaj wspaniały.\tChodź tutaj wspaniały działania\n"
     ]
    }
   ],
   "source": [
    "test_sentences(sentences_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Devise a method to test long-range relationships such as gender. E.e. you can use two verbs where withe masculine and feminine gender, where one of the verbs is masked. Both verbs should have the same gender, assuming the subject is the same. Define at least 3 such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    f'Poszedłem do pracy i {MASK} tam cały dzień',\n",
    "    f'Zobaczyła go z daleka i {MASK} za nim',\n",
    "    f'{MASK} tam i zobacz co się dzieje'\n",
    "]\n",
    "\n",
    "sentences_dot = [\n",
    "    f'Poszedłem do pracy i {MASK} tam cały dzień.',\n",
    "    f'Zobaczyła go z daleka i {MASK} za nim.',\n",
    "    f'{MASK} tam i zobacz co się dzieje.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "bert-base-multilingual-cased:\tPoszedłem do pracy i to tam cały dzień\tPoszedłem do pracy i jest tam cały dzień\tPoszedłem do pracy i tam tam cały dzień\tPoszedłem do pracy i gra tam cały dzień\tPoszedłem do pracy i ma tam cały dzień\n",
      "xlm-roberta-base:\tPoszedłem do pracy i był tam cały dzień\tPoszedłem do pracy i miałem tam cały dzień\tPoszedłem do pracy i jestem tam cały dzień\tPoszedłem do pracy i będę tam cały dzień\tPoszedłem do pracy i pracował tam cały dzień\n",
      "distilbert-base-multilingual-cased:\tPoszedłem do pracy i pracy tam cały dzień\tPoszedłem do pracy i pracował tam cały dzień\tPoszedłem do pracy i było tam cały dzień\tPoszedłem do pracy i przez tam cały dzień\tPoszedłem do pracy i 寓 tam cały dzień\n",
      "####################\n",
      "bert-base-multilingual-cased:\tZobaczyła go z daleka i była za nim\tZobaczyła go z daleka i to za nim\tZobaczyła go z daleka i miała za nim\tZobaczyła go z daleka i tylko za nim\tZobaczyła go z daleka i ta za nim\n",
      "xlm-roberta-base:\tZobaczyła go z daleka i była za nim\tZobaczyła go z daleka i zaraz za nim\tZobaczyła go z daleka i jeszcze za nim\tZobaczyła go z daleka i dokładnie za nim\tZobaczyła go z daleka i stał za nim\n",
      "distilbert-base-multilingual-cased:\tZobaczyła go z daleka i jest za nim\tZobaczyła go z daleka i tylko za nim\tZobaczyła go z daleka i jeszcze za nim\tZobaczyła go z daleka i brak za nim\tZobaczyła go z daleka i dana za nim\n",
      "####################\n",
      "bert-base-multilingual-cased:\ti tam i zobacz co się dzieje\tI tam i zobacz co się dzieje\tto tam i zobacz co się dzieje\t, tam i zobacz co się dzieje\tjest tam i zobacz co się dzieje\n",
      "xlm-roberta-base:\tKlik tam i zobacz co się dzieje\tStop tam i zobacz co się dzieje\tZobacz tam i zobacz co się dzieje\tZi tam i zobacz co się dzieje\tGo tam i zobacz co się dzieje\n",
      "distilbert-base-multilingual-cased:\tJest tam i zobacz co się dzieje\tJak tam i zobacz co się dzieje\tNie tam i zobacz co się dzieje\tpunk tam i zobacz co się dzieje\tjest tam i zobacz co się dzieje\n"
     ]
    }
   ],
   "source": [
    "test_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "bert-base-multilingual-cased:\tPoszedłem do pracy i to tam cały dzień.\tPoszedłem do pracy i jest tam cały dzień.\tPoszedłem do pracy i było tam cały dzień.\tPoszedłem do pracy i pracy tam cały dzień.\tPoszedłem do pracy i tym tam cały dzień.\n",
      "xlm-roberta-base:\tPoszedłem do pracy i był tam cały dzień.\tPoszedłem do pracy i miałem tam cały dzień.\tPoszedłem do pracy i pracował tam cały dzień.\tPoszedłem do pracy i jestem tam cały dzień.\tPoszedłem do pracy i stał tam cały dzień.\n",
      "distilbert-base-multilingual-cased:\tPoszedłem do pracy i pracował tam cały dzień.\tPoszedłem do pracy i pracy tam cały dzień.\tPoszedłem do pracy i školu tam cały dzień.\tPoszedłem do pracy i zmarł tam cały dzień.\tPoszedłem do pracy i było tam cały dzień.\n",
      "####################\n",
      "bert-base-multilingual-cased:\tZobaczyła go z daleka i była za nim.\tZobaczyła go z daleka i to za nim.\tZobaczyła go z daleka i została za nim.\tZobaczyła go z daleka i miała za nim.\tZobaczyła go z daleka i tam za nim.\n",
      "xlm-roberta-base:\tZobaczyła go z daleka i była za nim.\tZobaczyła go z daleka i idzie za nim.\tZobaczyła go z daleka i została za nim.\tZobaczyła go z daleka i jeszcze za nim.\tZobaczyła go z daleka i zaraz za nim.\n",
      "distilbert-base-multilingual-cased:\tZobaczyła go z daleka i jest za nim.\tZobaczyła go z daleka i brak za nim.\tZobaczyła go z daleka i pracował za nim.\tZobaczyła go z daleka i tylko za nim.\tZobaczyła go z daleka i jeszcze za nim.\n",
      "####################\n",
      "bert-base-multilingual-cased:\tTo tam i zobacz co się dzieje.\tJest tam i zobacz co się dzieje.\tJa tam i zobacz co się dzieje.\tjest tam i zobacz co się dzieje.\tTam tam i zobacz co się dzieje.\n",
      "xlm-roberta-base:\tStop tam i zobacz co się dzieje.\tKlik tam i zobacz co się dzieje.\tZi tam i zobacz co się dzieje.\tZobacz tam i zobacz co się dzieje.\tKom tam i zobacz co się dzieje.\n",
      "distilbert-base-multilingual-cased:\tJest tam i zobacz co się dzieje.\tZostał tam i zobacz co się dzieje.\tNie tam i zobacz co się dzieje.\tjest tam i zobacz co się dzieje.\tTak tam i zobacz co się dzieje.\n"
     ]
    }
   ],
   "source": [
    "test_sentences(sentences_dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Check if the model captures real-world knolwedge. For instance a sentence \"`[MASK]` wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\" checks if the model \"knows\" the description of water. Define at least 3 such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    f'Ziemia to {MASK} planeta od Słońca',\n",
    "    f'Najwyższą górą na Ziemi jest {MASK}',\n",
    "    f'Kod genetyczny komórki przechowywany jest w jej {MASK}'\n",
    "]\n",
    "\n",
    "sentences_long = [\n",
    "    f'Ziemia, nazywana niebieską planetą, to {MASK} planeta od Słońca',\n",
    "    f'Najwyższą górą na Ziemi jest {MASK} o wysokości 8848 m n.p.m.',\n",
    "    f'Kod genetyczny komórki przechowywany jest w jej {MASK} w postaci łańcuchów DNA'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "bert-base-multilingual-cased:\tZiemia to druga planeta od Słońca\tZiemia to to planeta od Słońca\tZiemia to ta planeta od Słońca\tZiemia to jedna planeta od Słońca\tZiemia to od planeta od Słońca\n",
      "xlm-roberta-base:\tZiemia to druga planeta od Słońca\tZiemia to większa planeta od Słońca\tZiemia to jedna planeta od Słońca\tZiemia to mniej planeta od Słońca\tZiemia to bliżej planeta od Słońca\n",
      "distilbert-base-multilingual-cased:\tZiemia to druga planeta od Słońca\tZiemia to pierwsza planeta od Słońca\tZiemia to jedna planeta od Słońca\tZiemia to tylko planeta od Słońca\tZiemia to nazwa planeta od Słońca\n",
      "####################\n",
      "bert-base-multilingual-cased:\tNajwyższą górą na Ziemi jest :\tNajwyższą górą na Ziemi jest.\tNajwyższą górą na Ziemi jest to\tNajwyższą górą na Ziemi jest góry\tNajwyższą górą na Ziemi jest -\n",
      "xlm-roberta-base:\tNajwyższą górą na Ziemi jest:\tNajwyższą górą na Ziemi jest...\tNajwyższą górą na Ziemi jest...\tNajwyższą górą na Ziemi jest\tNajwyższą górą na Ziemi jest.\n",
      "distilbert-base-multilingual-cased:\tNajwyższą górą na Ziemi jest :\tNajwyższą górą na Ziemi jest.\tNajwyższą górą na Ziemi jest ;\tNajwyższą górą na Ziemi jest to\tNajwyższą górą na Ziemi jest?\n",
      "####################\n",
      "bert-base-multilingual-cased:\tKod genetyczny komórki przechowywany jest w jej obrębie\tKod genetyczny komórki przechowywany jest w jej czasie\tKod genetyczny komórki przechowywany jest w jej trakcie\tKod genetyczny komórki przechowywany jest w jej języku\tKod genetyczny komórki przechowywany jest w jej rodzinie\n",
      "xlm-roberta-base:\tKod genetyczny komórki przechowywany jest w jej pamięci\tKod genetyczny komórki przechowywany jest w jej\tKod genetyczny komórki przechowywany jest w jej...\tKod genetyczny komórki przechowywany jest w jej...\tKod genetyczny komórki przechowywany jest w jej DNA\n",
      "distilbert-base-multilingual-cased:\tKod genetyczny komórki przechowywany jest w jej skład\tKod genetyczny komórki przechowywany jest w jej składzie\tKod genetyczny komórki przechowywany jest w jej wyniku\tKod genetyczny komórki przechowywany jest w jej rodzaju\tKod genetyczny komórki przechowywany jest w jej ramach\n"
     ]
    }
   ],
   "source": [
    "test_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "bert-base-multilingual-cased:\tZiemia, nazywana niebieską planetą, to jest planeta od Słońca\tZiemia, nazywana niebieską planetą, to to planeta od Słońca\tZiemia, nazywana niebieską planetą, to druga planeta od Słońca\tZiemia, nazywana niebieską planetą, to więc planeta od Słońca\tZiemia, nazywana niebieską planetą, to : planeta od Słońca\n",
      "xlm-roberta-base:\tZiemia, nazywana niebieską planetą, to druga planeta od Słońca\tZiemia, nazywana niebieską planetą, to większa planeta od Słońca\tZiemia, nazywana niebieską planetą, to pierwsza planeta od Słońca\tZiemia, nazywana niebieską planetą, to główna planeta od Słońca\tZiemia, nazywana niebieską planetą, to jedna planeta od Słońca\n",
      "distilbert-base-multilingual-cased:\tZiemia, nazywana niebieską planetą, to druga planeta od Słońca\tZiemia, nazywana niebieską planetą, to pierwsza planeta od Słońca\tZiemia, nazywana niebieską planetą, to jedna planeta od Słońca\tZiemia, nazywana niebieską planetą, to tylko planeta od Słońca\tZiemia, nazywana niebieską planetą, to jest planeta od Słońca\n",
      "####################\n",
      "bert-base-multilingual-cased:\tNajwyższą górą na Ziemi jest Ziemi o wysokości 8848 m n. p. m.\tNajwyższą górą na Ziemi jest Mons o wysokości 8848 m n. p. m.\tNajwyższą górą na Ziemi jest Alp o wysokości 8848 m n. p. m.\tNajwyższą górą na Ziemi jest Mars o wysokości 8848 m n. p. m.\tNajwyższą górą na Ziemi jest Maud o wysokości 8848 m n. p. m.\n",
      "xlm-roberta-base:\tNajwyższą górą na Ziemi jest Everest o wysokości 8848 m n.p.m.\tNajwyższą górą na Ziemi jest Malta o wysokości 8848 m n.p.m.\tNajwyższą górą na Ziemi jest szczyt o wysokości 8848 m n.p.m.\tNajwyższą górą na Ziemi jest Kilimanjaro o wysokości 8848 m n.p.m.\tNajwyższą górą na Ziemi jest wysokość o wysokości 8848 m n.p.m.\n",
      "distilbert-base-multilingual-cased:\tNajwyższą górą na Ziemi jest plutôt o wysokości 8848 m n. p. m.\tNajwyższą górą na Ziemi jest Gora o wysokości 8848 m n. p. m.\tNajwyższą górą na Ziemi jest Election o wysokości 8848 m n. p. m.\tNajwyższą górą na Ziemi jest punkt o wysokości 8848 m n. p. m.\tNajwyższą górą na Ziemi jest basen o wysokości 8848 m n. p. m.\n",
      "####################\n",
      "bert-base-multilingual-cased:\tKod genetyczny komórek przechowywany jest w ich czasie w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich trakcie w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich obrębie w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich sposób w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich lub w łańcuchach DNA\n",
      "xlm-roberta-base:\tKod genetyczny komórek przechowywany jest w ich pamięci w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich DNA w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich przypadku w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich obecności w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich postaci w łańcuchach DNA\n",
      "distilbert-base-multilingual-cased:\tKod genetyczny komórek przechowywany jest w ich przypadku w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich miejsce w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich wyniku w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich składzie w łańcuchach DNA\tKod genetyczny komórek przechowywany jest w ich skład w łańcuchach DNA\n"
     ]
    }
   ],
   "source": [
    "test_sentences(sentences_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Take into accout the fact, that causal language models such as PapuGaPT2 or plT5, will only generate continuations of the sentenes, so the\n",
    "   examples have to be created according to that paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Answer the following questions:\n",
    "   1. Which of the models produced the best results?\n",
    "   1. Was any of the models able to capture Polish grammar?\n",
    "   1. Was any of the models able to capture long-distant relationships between the words?\n",
    "   1. Was any of the models able to capture world knowledge?\n",
    "   1. What are the most striking errors made by the models?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
