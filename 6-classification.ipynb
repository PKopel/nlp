{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get acquainted with the data of the [Polish Cyberbullying detection dataset](https://huggingface.co/datasets/poleval2019_cyberbullying). \n",
    "   Pay special attention to the distribution of the positive and negative examples in the first task as well as\n",
    "   distribution of the classes in the second task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train the following classifiers on the training sets (for the task 1 and the task 2):\n",
    "   1. Bayesian classifier with TF * IDF weighting.\n",
    "   1. Fasttext text classifier\n",
    "   1. Transformer classifier (take into account that a number of experiments should be performed for this model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compare the results of classification on the test set. Select the appropriate measures (from accuracy, F1,\n",
    "   macro/micro F1, MCC) to compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Select 1 TP, 1 TN, 1 FP and 1 FN from your predictions (for the best classifier) and compare the decisions of each\n",
    "   classifier on these examples using [LIME](https://github.com/marcotcr/lime)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Answer the following questions:\n",
    "   1. Which of the classifiers works the best for the task 1 and the task 2.\n",
    "   1. Did you achieve results comparable with the results of [PolEval Task](http://2019.poleval.pl/index.php/results/)?\n",
    "   1. Did you achieve results comparable with the [Klej leaderboard](https://klejbenchmark.com/leaderboard/)?\n",
    "   1. Describe strengths and weaknesses of each of the compared algorithms.\n",
    "   1. Do you think comparison of raw performance values on a single task is enough to assess the value of a given\n",
    "      algorithm/model?\n",
    "   1. Did LIME show that the models use valuable features/words when performing their decision?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
